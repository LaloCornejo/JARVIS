jarvis:
  name: "JARVIS"
  wake_word: "hey jarvis"
  timezone: "America/Mexico_City"  # Your local timezone

llm:
  backend: ollama
  api_url: http://localhost:11434
  primary_model: qwen3:1.7b
  fast_model: qwen3:1.7b
  fallback_model: qwen3:1.7b
  temperature: 0.7
  stream: true

gemini:
  api_key_env: GEMINI_API_KEY
  default_model: gemini-2.5-flash
  vision_model: gemini-2.5-flash
  models:
    - gemini-2.5-flash
    - gemini-2.5-pro

ollama:
  api_url: http://localhost:11434
  vision_model: huihui_ai/qwen3-vl-abliterated:8b-instruct
  fast_model: qwen3:1.7b
  preload: true

voice_input:
  stt_backend: faster-whisper
  model: base.en
  device: cuda
  compute_type: float16
  vad: silero
  silence_duration: 0.5
  input_device: null # Use default device

tts:
  engine: xtts
  base_url: http://localhost:8020
  speaker: duckie
  language: en
  sample_rate: 24000

browser:
  default: zen
  automation: playwright

tools:
  enabled:
    - web_search
    - time
    - memory
    - file_search
    - system_control
  require_approval:
    - file_modify
    - system_settings
    - terminal

memory:
  vector_db: lancedb
  embedding_model: all-MiniLM-L6-v2
  db_path: ./data/vectors

security:
  offline_mode: false
  encrypt_memory: true
  terminal_whitelist:
    - ls
    - cat
    - grep
    - python

# MCP (Model Context Protocol) Configuration
mcp:
  enabled: true
  auto_connect: true
  
  servers:
    # Tier 1: Essential (Official MCP Servers)
    filesystem:
      enabled: true
      command: npx
      args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
      env: {}
    
    fetch:
      enabled: true
      command: npx
      args: ["-y", "@modelcontextprotocol/server-fetch"]
      env: {}
    
    github:
      enabled: false  # Requires GITHUB_PERSONAL_ACCESS_TOKEN
      command: npx
      args: ["-y", "@modelcontextprotocol/server-github"]
      env:
        GITHUB_PERSONAL_ACCESS_TOKEN: ""  # Set via env var
    
    sequentialthinking:
      enabled: true
      command: npx
      args: ["-y", "@modelcontextprotocol/server-sequentialthinking"]
      env: {}
    
    memory:
      enabled: true
      command: npx
      args: ["-y", "@modelcontextprotocol/server-memory"]
      env: {}
    
    # Tier 2: Highly Valuable
    sqlite:
      enabled: true
      command: npx
      args: ["-y", "@modelcontextprotocol/server-sqlite", "./data/jarvis.db"]
      env: {}
    
    redis:
      enabled: false  # Requires Redis server running
      command: npx
      args: ["-y", "@modelcontextprotocol/server-redis"]
      env:
        REDIS_URL: "redis://localhost:6379"
    
    playwright:
      enabled: true
      command: npx
      args: ["-y", "@anthropic-ai/mcp-playwright"]
      env: {}
    
    # Third-party/community servers
    context7:
      enabled: true
      command: npx
      args: ["-y", "@upstash/context7-mcp"]
      env: {}
    
    exa:
      enabled: false  # Requires EXA_API_KEY
      command: npx
      args: ["-y", "@exa-labs/mcp"]
      env:
        EXA_API_KEY: ""  # Set via env var
    
    browserbase:
      enabled: false  # Requires BROWSERBASE_API_KEY
      command: npx
      args: ["-y", "@browserbasehq/mcp-server-browserbase"]
      env:
        BROWSERBASE_API_KEY: ""
        BROWSERBASE_PROJECT_ID: ""
